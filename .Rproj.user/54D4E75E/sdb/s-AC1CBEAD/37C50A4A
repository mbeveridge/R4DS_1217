{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Chapter05\"\noutput:\n  github_document: default\n  html_notebook: default\n---\n\n```{r}\n# install.packages(\"nycflights13\")\nlibrary(nycflights13) # dataset on flights departing New York City in 2013\nlibrary(tidyverse)\n```\n\n\n## 5. \"Data transformation\" [Chapter 3 hardcopy]\n### 5.2.4 Exercises\n  \nQ1.\nFind all flights that :\nQ1.1 Had an arrival delay of two or more hours\nQ1.2 Flew to Houston (IAH or HOU)\nQ1.3 Were operated by United, American, or Delta\nQ1.4 Departed in summer (July, August, and September)\nQ1.5 Arrived more than two hours late, but didn’t leave late\nQ1.6 Were delayed by at least an hour, but made up over 30 minutes in flight\nQ1.7 Departed between midnight and 6am (inclusive)\n\nA1.\n```{r}\nflights # 336776 rows\nglimpse(flights)\n\nfilter(flights, arr_delay >= 120) # A1.1 ...10200 rows\nfilter(flights, dest == \"IAH\" | dest == \"HOU\")  # A1.2 ...9313 rows\nfilter(flights, dest %in% c(\"IAH\", \"HOU\")) # A1.2 alternate ...9313 rows\nfilter(flights, carrier %in% c(\"UA\", \"AA\", \"DL\")) # A1.3 ...139504 rows\nfilter(flights, month %in% c(7, 8, 9)) # A1.4 ...86326 rows\nfilter(flights, arr_delay > 120, dep_delay <= 0) # A1.5 ...29 rows\nfilter(flights, dep_delay >= 60, dep_delay - arr_delay >= 30) # A1.6 ...2074 rows\nfilter(flights, dep_time >= 0000, dep_time <= 0600) # A1.7 ...9344 rows\n```\n\n-----------\n\nQ2.\nAnother useful **dplyr** filtering helper is `between()`. What does it do?\nCan you use it to simplify the code needed to answer the previous challenges?\n\nA2.\n```{r}\n?between # This is a shortcut for x >= left & x <= right\n\nfilter(flights, between(month, 7, 9)) # A1.4 ...86326 rows\nfilter(flights, between(dep_time, 0000, 0600)) # A1.7 ...9344 rows\n```\n\n-----------\n\nQ3.\nHow many flights have a missing `dep_time`? What other variables are missing?\nWhat might these rows represent?\n\nA3.\n`filter(flights, dep_time == NA)` ...doesn't work : \"A tibble: 0 x 19\"\n\n```{r}\nfilter(flights, is.na(dep_time)) # 8255 rows\n```\n* Arrival time (and departure/arrival delay) also missing.\n* These rows are probably cancelled flights\n\n-----------\n\nQ4.\nQ4.1 Why is `NA ^ 0` not missing?\nQ4.2 Why is `NA | TRUE` not missing?\nQ4.3 Why is `FALSE & NA` not missing?\nQ4.4 Can you figure out the general rule? (`NA * 0` is a tricky counterexample!)\n\nA4. [In practice, expressions will evaluate to these things. Try running them, to confirm outcome]\nA4.1 `NA ^ 0 == 1`, because any numeric value to the 0th power equals 1. (So we know result is 1)\nA4.2 One of the 'OR' expressions is TRUE, so the other doesn't affect the outcome. (So we know result is TRUE)\nA4.3 One of the 'AND' expressions is FALSE, so the other doesn't affect the outcome. (So we know result is FALSE)\nA4.4 \"In operations, any value interacting with an NA becomes missing. Missing values are ignored in conditional expressions\". (`NA * 0` evaluates to `NA`, instead of the 'zero' that might be expected. +/- infinity can be multiplied by 0 and not evaluate to 0 ...but I don't know if that's the reason `NA` was chosen as the output)\n\n\n-----------\n\n## 5. \"Data transformation\" [Chapter 3 hardcopy]\n### 5.3.1 Exercises\n  \nQ1. How could you use `arrange()` to sort all missing values to the start? (Hint: use `is.na()`)\n\nA1.\n```{r}\narrange(flights, !is.na(dep_time)) # In 5.2.4 Exercises Q3 we said some \"flights have a missing `dep_time`\"\n```\nRows with `dep_time` missing will return a value of FALSE (0), so will be at start\n\n-----------\n\nQ2.\n\n* Sort `flights` to find the most delayed flights\n* Find the flights that left earliest\n\nA2.\n```{r}\narrange(flights, desc(arr_delay)) # 1272 minutes on 2013-01-09\n\narrange(flights, dep_delay) # 43 minutes early on 2013-12-07\n```\n\n-----------\n\nQ3. Sort `flights` to find the fastest flights\n\nA3.\n```{r}\narrange(flights, desc(distance / air_time)) # flight=1499 on 2013-05-25\n```\n\n-----------\n\nQ4.\nWhich flights travelled the longest?\nWhich travelled the shortest?\n\nA4.\n```{r}\narrange(flights, desc(distance)) # Various at 4983 miles\n\narrange(flights, distance) # One at 17 miles (if valid), and various at 80 miles\n```\n\n\n-----------\n\n## 5. \"Data transformation\" [Chapter 3 hardcopy]\n### 5.4.1 Exercises\n  \nQ1. Brainstorm as many ways as possible to select `dep_time`, `dep_delay`, `arr_time`, and `arr_delay` from `flights`\n\nA1.\n```{r}\nselect(flights, dep_time, dep_delay, arr_time, arr_delay)\nselect(flights, starts_with(\"dep\"), starts_with(\"arr\"))\nselect(flights, ends_with(\"_time\"), ends_with(\"_delay\")) # though this also gives `sched_dep_time`, `sched_arr_time` and `air_time`\nselect(flights, ends_with(\"time\"), ends_with(\"delay\"), -(starts_with(\"sched\")), -(starts_with(\"air\")))\nselect(flights, contains(\"dep_\"), contains(\"arr_\")) # though this also gives `sched_dep_time` and `sched_arr_time`\nselect(flights, contains(\"dep\"), contains(\"arr_\"), -(contains(\"sched\")))\nselect(flights, matches(\"^(dep|arr)_(time|delay)$\")) # Regex [https://jrnold.github.io/r4ds-exercise-solutions/data-transformation.html#arrange]\n```\n\n-----------\n\nQ2. What happens if you include the name of a variable multiple times in a `select()` call?\n\nA2.\n```{r}\nselect(flights, dep_time, dep_time, dep_time)\n```\nThe variable is included only once in the new data frame. (No error/warning messages)\n\n-----------\n\nQ3 What does the `one_of()` function do? Why might it be helpful in conjunction with this vector?\n`vars <- c(\"year\", \"month\", \"day\", \"dep_delay\", \"arr_delay\")`\n\nA3.\n```{r}\n?one_of()\n\nvars <- c(\"year\", \"month\", \"day\", \"dep_delay\", \"arr_delay\")\nselect(flights, one_of(vars))\n```\n\n* It selects any variable which matches one of those in the vector\n* It’s useful because then you can easily pass vectors to `select()`\nPS. as a memory-jogger : In `filter()` we had `%in% c(,,)`\n\n-----------\n\nQ4.\nDoes the result of running the following code surprise you?\nHow do the select helpers deal with case by default? How can you change that default?\n```{r}\nselect(flights, contains(\"TIME\"))\n```\n\n\nA4.\nBy default the `select()` helpers ignore case\nTo change that, set `ignore.case = FALSE` in the helper function. (Then, no variables are selected - see 'blank' tibble below)\n```{r}\nselect(flights, contains(\"TIME\", ignore.case = FALSE)) # eg. for `contains()`\n```\n\n\n-----------\n\n## 5. \"Data transformation\" [Chapter 3 hardcopy]\n### 5.5.2 Exercises\n  \nQ1.\nCurrently `dep_time` and `sched_dep_time` are convenient to look at, but hard to compute with\nbecause they’re not really continuous numbers. \nConvert them to a more convenient representation of number of minutes since midnight\n\nA1.\n```{r}\ntransmute(flights, dep_time = (dep_time %/% 100) * 60 + dep_time %% 100, sched_dep_time = (sched_dep_time %/% 100) * 60 + sched_dep_time %% 100) # eg. Originally `dep_time` of 5:17am shown as 517. Now as 317 mins since midnight\n```\n\n-----------\n\nQ2.\nCompare `air_time` with `arr_time - dep_time`.\nWhat do you expect to see? What do you see? What do you need to do to fix it?\n\nA2.\n```{r}\ntransmute(flights, air_time, arr_time, dep_time, arr_time - dep_time)\n```\nExpect that `air_time` equals `arr_time - dep_time` in 'reality'. But from Q1 we know that the original representation prevents that computation\n\nTo fix it we can do the same conversion as in A1 :\n```{r}\ntransmute(flights, air_time, air_time_new = ((arr_time %/% 100) * 60 + arr_time %% 100) - ((dep_time %/% 100) * 60 + dep_time %% 100)) # `air_time_new` is calculated (after conversion), and `air_time` exists from original dataset\n```\n\n* HOWEVER, `air_time` 'still' doesn't equal `air_time_new`. Why not?\n* My `air_time_new` values are correct (ie. calc same as some online answers). **How are `air_time` values obtained??**\n* Some flights may cross timezones (and arrival and departure times are reported in local time)\n* Some flights may leave before midnight and arrive after (giving large -ve values)\n* But (without yet including the latter 2 effects in my calculation) the differences I still see are rarely a multiple of 60 (nor half etc), so is this worth pursuing, or will I never match to the `air_time` number with available info ?\n\n-----------\n\nQ3.\nCompare `dep_time`, `sched_dep_time`, and `dep_delay`.\nHow would you expect those three numbers to be related?\n\nA3.\n```{r}\nselect(flights, dep_time, sched_dep_time, dep_delay)\n```\n`dep_time = sched_dep_time + dep_delay` ...If we convert `dep_time` and `sched_dep_time` to minutes past midnight, etc etc\n\n-----------\n\nQ4.\nFind the 10 most delayed flights using a ranking function.\nHow do you want to handle ties? Carefully read the documentation for `min_rank()`\n\nA4.\n```{r}\narrange(flights, min_rank(desc(arr_delay))) # Didn't use filter() here, but 10 results displayed by default\nfilter(flights, min_rank(desc(dep_delay)) <= 10) # Only 10 results (there were no ties), but not in order\n\n?min_rank\n```\n\n`min_rank()` \"does the most usual type of ranking (e.g. 1st, 2nd, 2nd, 4th)\" -- Book text. ...So there could be >10 rows, if ties\n\nUsing pipes (which we haven't covered in the book yet, but are just about to), we could \"Find the 10 most delayed flights\" (and also show the rank) like this :\n```{r}\nflights %>% \n  mutate(rank = min_rank(desc(dep_delay))) %>%\n  arrange(rank)\n```\n\n-----------\n\nQ5. What does 1:3 + 1:10 return? Why?\n\nA5.\n```{r}\n1:3 + 1:10\n```\n\n* Vector of (2,4,6,5,7,9,8,10,12,11) and Warning message \"longer object length is not a multiple of shorter object length\"\n* (The two vectors are not the same length, so R 'recycles' the shorter one until each vector is the same length)\n* Because 10 doesn't divide exactly by 3, the vectors do not line up properly and we get a Warning\n\n-----------\n\nQ6. What trigonometric functions does R provide?\n\nA6.\n```{r}\n?Trig\n```\n\n* `cos(x)`, `sin(x)`, `tan(x)`\n* `acos(x)`, `asin(x)`, `atan(x)`, `atan2(y, x)`\n* `cospi(x)`, `sinpi(x)`, `tanpi(x)`\n\n\n-----------\n\n## 5. \"Data transformation\" [Chapter 3 hardcopy]\n### 5.6.7 Exercises\n\nQ1: Brainstorm at least 5 different ways to assess the typical delay characteristics\nof a group of flights. Consider the following scenarios:\n\nQ1.1 A flight is 15 minutes early 50% of the time, and 15 minutes late 50% of the time.\nQ1.2 A flight is always 10 minutes late.\nQ1.3 A flight is 30 minutes early 50% of the time, and 30 minutes late 50% of the time.\nQ1.4 99% of the time a flight is on time. 1% of the time it’s 2 hours late.\nQ1.5 Which is more important: arrival delay or departure delay?\n\nA1.\nA1.1 A flight is 15 minutes early 50% of the time, and 15 minutes late 50% of the time :\n```{r}\nflights %>%\n  group_by(flight) %>%\n  summarise(early_15min = sum(arr_delay == -15, na.rm = TRUE) / n(),\n            late_15min = sum(arr_delay == 15, na.rm = TRUE) / n()) %>%\n  filter(early_15min == 0.5, late_15min == 0.5)\n```\nA1.1 This gives zero rows (flight numbers)\n\nA1.1 A flight is >=15 minutes early 50% of the time, and >=15 minutes late 50% of the time :\n```{r}\nflights %>%\n  group_by(flight) %>%\n  summarise(early_15min = sum(arr_delay <= -15, na.rm = TRUE) / n(),\n            late_15min = sum(arr_delay >= 15, na.rm = TRUE) / n()) %>%\n  filter(early_15min == 0.5, late_15min == 0.5)\n```\nA1.1 This gives 18 rows (flight numbers)\n\nA1.1 using `mean()` instead of `sum()/n()` :\n```{r}\nView(flights %>%\n  group_by(flight) %>%\n  summarise(early_15min = mean(arr_delay <= -15, na.rm = TRUE),\n            late_15min = mean(arr_delay >= 15, na.rm = TRUE)) %>%\n  filter(early_15min == 0.5, late_15min == 0.5))\n```\nA1.1 This gives 21 rows ...including flight=3505, flight=4436, flight=5910 not got with `sum()/n()`. [See below]\n\n```{r}\nflights %>%\n  filter(flight == 3505) # as an example, to see why it is treated differently by mean() v's sum()/n()\n```\nA1.1 `sum()/n()` removes the `NA` row from the `sum()`, but not from the `n()`, so we have a count of 3 rows and don't end up with 0.5 as the mean/proportion (but 0.33), and don't see flight=3505. However, `mean()` removes `NA` and so only considers 2 rows. Neither answer is definitely right/wrong, and you have to decide what you really want to know]\n\n\nA1.2 A flight is always 10 minutes late :\n```{r}\nflights %>%\n  group_by(flight) %>%\n  summarise(late_10min = sum(arr_delay == 10, na.rm = TRUE) / n()) %>%\n  filter(late_10min == 1)\n```\nA1.2 This gives 4 rows : flight=2254, 3656, 3880, 5854\n\n\nA1.3 A flight is 30 minutes early 50% of the time, and 30 minutes late 50% of the time :\n```{r}\nflights %>%\n  group_by(flight) %>%\n  summarise(early_30min = sum(arr_delay <= -30, na.rm = TRUE) / n(),\n            late_30min = sum(arr_delay >= 30, na.rm = TRUE) / n()) %>%\n  filter(early_30min == 0.5, late_30min == 0.5)\n```\nA1.3 This gives 3 rows : flight=3651, 3916, 3951\n\n\nA1.4 99% of the time a flight is on time. 1% of the time it's 2 hours late :\n```{r}\nflights %>%\n  group_by(flight) %>%\n  summarise(on_time = sum(arr_delay == 0, na.rm = TRUE) / n(),\n            late_120min = sum(arr_delay >= 120, na.rm = TRUE) / n()) %>%\n  filter(on_time == .99, late_120min == .01)\n```\nA1.4 This gives zero rows, even though I made '2 hours late' looser (ie. 2 hours or more)\n\n\nA1.5 Which is more important: arrival delay or departure delay? :\n[Q1 didn't seem to require calculations, just that we consider what different 'clusters'/ summaries might exist, and whether they might be important. I did the calculations above for practice, and to see the quantities involved]\n\n* For an individual, it's personal preference (eg. extra time in air v's extra time waiting at airport,\n or need to be at a meeting on time)\n* For an individual, it may also depend on certainty (low variance) for that flight. (Could you arrive late IF gate stays open, and could you plan/book onward travel 'knowing' what the delay might be?)\n* For an airport/(airline), both could affect capacity planning & wastage & customer compensation, and again certainty (low variance) would be important\n* For both (and for specific flightroute, or overall group), we could create scatterplot (delay v's count) as in s5.6.3. And/or could create an aggregate calculation of 'typical' delay (taking account probability)\n\n-----------\n\nQ2.\nCome up with another approach that will give you the same output as `not_cancelled %>% count(dest)`\nand `not_cancelled %>% count(tailnum, wt = distance)` (without using `count()`)\n\nA2. [We have this definition of `not cancelled` from s5.6.2 in the book text] :\n```{r}\nnot_cancelled <- flights %>% \n  filter(!is.na(dep_delay), !is.na(arr_delay))\n```\n\nA2.1 cf. `not_cancelled %>% count(dest)` ...[104 rows x 2 cols (dest, n)]\n```{r}\nnot_cancelled %>%\n  group_by(dest) %>%\n  summarise(n())\n```\n\nA2.2 cf. `not_cancelled %>% count(tailnum, wt = distance)` ...[4037 rows x 2 cols (tailnum, n)]\n```{r}\nnot_cancelled %>%\n  group_by(tailnum) %>%\n  summarise(sum(distance))\n```\n\n-----------\n\nQ3.\nOur definition of cancelled flights (`is.na(dep_delay) | is.na(arr_delay)`) is slightly suboptimal.\nWhy? Which is the most important column?\n\nA3.\n```{r}\nflights %>%\n  group_by(!is.na(dep_delay), !is.na(arr_delay)) %>%\n  summarise(n())\n```\n\nThe data has some flights that departed but didn't arrive (so those weren't cancelled\nand shouldn't be excluded as such). It doesn't have any that arrived but didn't depart.\n**So the important column is `dep_delay`**, and our optimal definition of cancelled flights is now\n`(is.na(dep_delay)`\n\n-----------\n\nQ4.\nQ4.1 Look at the number of cancelled flights per day. Is there a pattern?\nQ4.2 Is the proportion of cancelled flights related to the average delay?\n\nA4.1\n```{r}\ncancelled <- flights %>%\n  filter(is.na(dep_delay)) %>%    # From A3: \"definition of cancelled flights is now `(is.na(dep_delay)`\"\n  group_by(year, month, day) %>%\n  summarise(count = n())\n```\n\n```{r}\nView(cancelled) # Can't tell a pattern from looking at this table. Try a chart...\n```\n\n```{r}\nggplot(data = cancelled, mapping = aes(x = day, y = count)) +\n  geom_point() # 31 days along x-axis (with one point per month). 2 days had a point with count=400ish : 8th & 9th\n\ndate_long <- paste(cancelled$year, cancelled$month, cancelled$day) # trying to get 365 days as complete dates\nggplot(data = cancelled, mapping = aes(x = date_long, y = count)) +\n  geom_point() # still 2 days with count=400ish : 8Feb and 9Feb. Why are these *midway* along x-axis?\n```\nThere is no obvious pattern. (IIRC, 8Feb and 9Feb are midway along because the months get sorted 1, 10, 11, 12, 2, etc ...so Feb is 5th of 12, which is midway-ish.) Below is a way to get the 2nd chart I wanted (but still no obvious pattern), and the two '#comments' there are mine :\n\n--------------------------\n_Comment & code from @michaeljw [to me, in R4DS Slack on board=03_week] on 20/9/17 ~16:15 :\n\nUsing `paste()` is a fine guess, but there's an even simpler way: the data frame has a column\ncalled `time_hour`, which contains the date and the time of the flight. You can use `as.Date()`\nto strip the time out, like so:_\n```{r}\ncancelled <- flights %>%\nfilter(is.na(dep_delay)) %>%\nmutate(date = as.Date(time_hour)) %>%    # This is an extra line (v's my attempt above)\ngroup_by(date) %>%                       # Instead of `group_by(year, month, day)`\nsummarise(count = n())\n```\n\n_Note that I've done this in a `mutate()` call so that the new `date` column is part of the `cancelled`\ndata frame. That will make it easier to use as the axis when plotting.\nThis `cancelled` data frame now just has `date` and `count` columns; with a small modification to\nyour original code we can plot them like so:_\n```{r}\nggplot(data = cancelled, mapping = aes(x = date, y = count)) +\n  geom_point()\n```\n\n--------------------------\n\n\nA4.2 [reminder: \"Is the proportion of cancelled flights related to the average delay?\"]\n```{r}\nflights %>%\n  group_by(year, month, day) %>%\n  summarise(cancelled = sum(is.na(dep_delay)),                        # define 'cancelled' ...not used\n            cancelled_propn = mean(is.na(dep_delay)),                 # define 'cancelled propn' ...for y-axis\n            mean_dep_delay = mean(dep_delay,na.rm=TRUE),              # define 'mean_dep_delay' ...for x-axis\n            mean_arr_delay = mean(arr_delay,na.rm=TRUE)) %>%          # define 'mean_arr_delay' ...for x-axis\n  ggplot(aes(y = cancelled_propn)) +\n  geom_point(aes(x=mean_dep_delay), colour='blue', alpha=0.5) +       # blue scatter (1 point per day)\n  geom_point(aes(x=mean_arr_delay), colour='red', alpha=0.5) +        # red scatter (1 point per day)\n  geom_smooth(aes(x=mean_dep_delay), colour='blue') +                 # blue line\n  geom_smooth(aes(x=mean_arr_delay), colour='red') +                  # red line\n  xlab('average delay (minutes)') +                                   # x-axis label (both arrival and departure)\n  ylab('proportion of cancelled flights')                             # y-axis label\n```\nYes. There is a +ve correlation between `proportion of cancelled flights` and `average delay`.\nSo (simplifying), on days with a lot of delays, there will also be a lot of cancellations\n\n-----------\n\nQ5.\nQ5.1 Which carrier has the worst delays?\nQ5.2 Challenge: can you disentangle the effects of bad airports vs. bad carriers?\nWhy/why not? (Hint: think about `flights %>% group_by(carrier, dest) %>% summarise(n())`)\n\nA5.1\n```{r}\nflights %>%\n  filter(!is.na(dep_delay), !is.na(arr_delay)) %>%\n  group_by(carrier) %>%\n  summarise(mean_arr_delay = mean(arr_delay)) %>% # `na.rm = TRUE` argument not needed, as `filter()` does similar\n  arrange(desc(mean_arr_delay))                   # ---> carrier=F9 is first on the list, with 22 minutes\n\nfilter(airlines, carrier == \"F9\")                 # 'Frontier Airlines Inc' is the carrier with worst average delay\n```\n\nA5.2 [reminder: \"can you disentangle the effects of bad airports vs. bad carriers? Why/why not?\"]\n```{r}\nflights %>% group_by(carrier) %>% summarise(n())       # 16 carriers\nflights %>% group_by(dest) %>% summarise(n())          # 105 destination airports\n\nflights %>% group_by(carrier, dest) %>% summarise(n()) # 314 rows. (+ Sometimes carrier-dest was only 1 or 2 times)\nflights %>% group_by(dest) %>% summarise(unique = n_distinct(carrier)) %>% arrange(desc(unique)) # s5.6.4 in book\n```\n...Thoughts from this brief look at the data :\n\n* We could try to disentangle the effects of bad carriers v's bad airports by comparing a specific carrier’s delay\n at a destination airport v's average delay at that airport (where latter has excluded that carrier's flights)\n* However, 53 of those 105 airports only receive 1 or 2 carriers (and max is 7), so it would be hard to disentangle\n* (NOTE: I haven't done any calculations, to actually try and disentangle the effects)\n\n-----------\n\nQ6. What does the `sort` argument to `count()` do. When might you use it?\n\nA6.\nThe `sort` argument will sort the results of `count()` in descending order of n.\nYou might use this (to save a line of code), if you want to `count()` and then `arrange()` the results\n...and you might want to do that because the most important results are often in the Top10\n\n\n-----------\n\n## 5. \"Data transformation\" [Chapter 3 hardcopy]\n### 5.7.1 Exercises\n\nQ1.\nRefer back to the lists of useful mutate and filtering functions.\nDescribe how each operation changes when you combine it with grouping\n\nA1.\n[Not sure which lists (but maybe s5.5.1 [creation functions] and s5.6.4 [summary functions]) ...eg. `min_rank()`, `rank()`, `n()`, `sum()`]\n[A5 [below] uses `lag()` in a `mutate()`; A6.1 uses `median()` in a `mutate()`; A6.2 uses `min()` in a `mutate()`; A7 uses `n_distinct()` in a `filter()` (and in a `summarise()`)]\n\nThe function operates within each group rather than over the entire data frame.\neg. `mean()` will calculate the mean within each group\n\n-----------\n\nQ2. Which plane (`tailnum`) has the worst on-time record?\n\nA2.\n```{r}\nflights %>%                                                  # 336,776 x 19\n  group_by(tailnum) %>%                                      # 336,776 x 19\n  summarise(arr_delay = mean(arr_delay, na.rm = TRUE)) %>%   # 4044 x 2 ...`tailnum` and the redefined `arr_delay`\n  filter(min_rank(desc(arr_delay)) == 1)                     # 1 x 2    ...taking just the first-ranked out of 4044\n```\n`tailnum` = N844MH has the highest average `arr_delay` ...320 minutes. (There are other ways we could define 'worst')\n\n-----------\n\nQ3. What time of day should you fly if you want to avoid delays as much as possible?\n\nA3. Grouping by hour, and visualising delays >15min (having tried a few alternate values)\n```{r}\nflights %>%\n  group_by(hour) %>%\n  summarise(arr_delay = sum(arr_delay > 15, na.rm = TRUE) / n()) %>%     # redefined `arr_delay`, as T/F proportion\n  ggplot(aes(x = hour, y = arr_delay)) +\n  geom_col()\n```\n\n* Flying midnight to 5am has zero chance of arrival delay (because no flights available?)\n* The later you fly the worse (peaking at 9pm). (Delays early in the morning have a knockon effect throughout the day. Etc)\n\n-----------\n\nQ4.\nQ4.1 For each destination, compute the total minutes of delay.\nQ4.2 For each flight, compute the proportion of the total delay for its destination\n\nA4.1\n```{r}\nflights %>%\n  filter(!is.na(arr_delay), arr_delay > 0) %>%        # 1st condition not really needed. Exclude -ve delays\n  group_by(dest) %>%\n# mutate(total_delay = sum(arr_delay)) %>%            # This row not needed. Can do it in `summarise`\n  summarise(total_delay = sum(arr_delay)) %>%\n  select(dest, total_delay)\n```\n\nA4.2 [reminder: \"For each flight, compute the proportion of the total delay for its destination\"]\n```{r}\nflights %>%\n  filter(!is.na(arr_delay), arr_delay > 0) %>%        # 133,004 x 19\n  group_by(dest, flight) %>%                          # 133,004 x 19. Groups: dest, flight [8505]\n  mutate(total_delay = sum(arr_delay),\n         prop_delay = arr_delay / total_delay) %>%    # 133,004 x 21. Groups: dest, flight [8505]\n# First I want `total_delay` for each flight within each dest. But how will I access total delay per dest, for proportion calc?\n  summarise(total_delay = sum(arr_delay),\n            prop_delay = arr_delay / total_delay) %>% # error: \"Column `prop_delay` must be length 1 (a summary value), not 52\"\n  select(dest, total_delay, flight, prop_delay)\n```\n\nMY ABOVE ATTEMPT DIDN'T WORK. (BUT a working solution is below, a reply to this/my request for help)\n\"I could do the first part in isolation. But the way I picture grouping might be a bit shaky, so I’m\nstruggling with rolling up (and when to use `ungroup()`, etc etc), and I seem to be at the point of ‘throwing\ncode, to see what sticks’, and lost. Can anyone give me pointers towards a solution?\"\n\nNote: I edited @jmoran's code [below], from `tailnum` to `flight`. And to include `filter(arr_delay > 0)`. And '#comments' there are mine\nPS. The solution relies on `left_join()`, which isn't a function we've met in the book yet\n\n--------------------------\n_Comment & code from @jmoran [to me, in R4DS Slack on board=03_week] on 21/9/17 13:10 :\n\nAnd for part 2, I did the following, which I think gets us the answer. It’s likely more steps than are needed.\n  \nCreate a table of total delays by 'destination' :_\n```{r}\ntotal_delay <- flights %>%\n  filter(arr_delay >= 0) %>%                                     # MDAB added\n  group_by(dest) %>%\n  dplyr::summarise(total_delay = sum(arr_delay, na.rm= TRUE))    # define `total_delay`\n```\n\n_Create a table of total delays by 'FLIGHT' for each destination. [MDAB: flight means 'Flight number', not an individual trip. Could be to multiple destinations] :_\n```{r}\nflight_delays <- flights %>%\n  filter(arr_delay >= 0) %>%                                     # MDAB added\n  group_by(flight, dest) %>%\n  dplyr::summarise(delay_per = sum(arr_delay, na.rm = TRUE))     # define `delay_per`\n```\n\n_Join the two tables (on `dest`) and create a 'proportion delay' column :_\n```{r}\nflight_delays <- flight_delays %>%\n  left_join(total_delay,by = \"dest\") %>%\n  mutate(prop_delay = delay_per / total_delay) %>%               # define `prop_delay\n  arrange(dest, flight)             # MDAB added, to sort by `dest` first, to see that each `dest` total adds to 1.0\n```\n\n```{r}\nflight_delays                       # 8620 x 5\n```\n\n--------------------------\n\n-----------\n\nQ5.\nDelays are typically temporally correlated: even once the problem that caused the initial delay has been resolved, later flights are delayed to allow earlier flights to leave.\nUsing `lag()` explore how the delay of a flight is related to the delay of the immediately preceding flight\n\nA5.\n```{r}\n?lag # See s5.5.1 of book text instead\n```\n\n* This relates to departures from each location, so use `dep_delay` and `origin`\n* ie. Want to compare flights from the same `origin`, not simply at consecutive times\n* Avoid comparing 05:00 flight with 23:59 flight. Grouping by day makes each 1st lag an `NA` (?) and can `filter()`\n* Filter out NA's before and after calculating the `lag_delay`\n\n```{r}\nflights %>%\n  group_by(year, month, day, origin) %>%\n  arrange(year, month, day, hour, minute) %>%         # sorting by hour & minute, within each group\n  filter(!is.na(dep_delay)) %>%\n  mutate(lag_delay = lag(dep_delay)) %>%              # define `lag_delay` for consecutive flights from an `origin`\n  filter(!is.na(lag_delay)) %>%                       # ...And now plot it...\n  ggplot(aes(x = dep_delay, y = lag_delay)) +\n  geom_point() +\n  geom_smooth()\n```\n\nNote: Wondering how much reliance to place on the geom_smooth line, as it was a similar shape when I (originally) had the x & y axes transposed\n\n-----------\n\nQ6.\nQ6.1 Look at each destination. Can you find flights that are suspiciously fast? (i.e. flights that represent a potential data entry error).\nQ6.2 Compute the air time of a flight relative to the shortest flight to that destination. Which flights were most delayed in the air?\n\nA6.1\n\n* Surely we can't just compare `air_time` to the median value for a destination - what about the fact\n that flights also have different `origin`/distance ?\n* Well, the dataset is \"dataset on flights departing New York City in 2013\", so it's probably ok (ie. any `origin` is near to every other `origin` airport)\n\n```{r}\nflights %>%\n  filter(!is.na(air_time)) %>%\n  group_by(dest) %>%\n  mutate(med_time = median(air_time),                   # define `med_time` (uses the group, but not `summarise()`)\n         fast = (air_time - med_time) / med_time) %>%   # define it relative to median for `dest`, as a PROPORTION\n  arrange(fast) %>%\n  select(dest, origin, year, month, day, carrier, flight, air_time, med_time, fast) %>%\n  head(20)\n```\n* Shorter flights might be disproportionately affected by delays of a few minutes (eg. circling above\n destination, waiting for permission to land, good/bad weather/wind?)\n* The flights at the top of the `fast` list have ~40% time savings, which is significant\n* Are all of the numbers entered (v's calculated)? I don't see (eg) transposition errors as indication\n that data entry is a problem\n\nA6.2 [reminder: \"Compute the air time of a flight relative to the shortest flight to that destination. Which flights were most delayed in the air?\"]\n\n* What does \"relative to the shortest flight to that destination\" mean? Are we supposed to ignore that\n flights also have different `origin`/distance? - it would give misleading 'delayed in the air' values.\n* Well, the dataset is \"dataset on flights departing New York City in 2013\", so it's probably ok (ie. any `origin` is near to every other `origin` airport)\n\n```{r}\nflights %>%\n  filter(!is.na(air_time)) %>%                              # [same as for A6.1]\n  group_by(dest) %>%                                        # [same as for A6.1]\n  mutate(air_time_relative = air_time - min(air_time)) %>%  # define it relative to minimum for `dest`, as ABSOLUTE\n  arrange(desc(air_time_relative)) %>%\n  select(dest, origin, year, month, day, carrier, flight, air_time, air_time_relative) %>%\n  head(20)\n```\n* The 2013-07-28 DL flight into SFO was 'most delayed'. carrier=DL into SFO and LAX shows up several times\n near the top of the 'most delayed' list (but flight numbers differ)\n* Is this what the question meant, or did the last part intend an average per flight?\n\n-----------\n\nQ7.\nFind all destinations that are flown by at least two carriers.\nUse that information to rank the carriers\n\nA7.\ncf. A5.2 : `flights %>% group_by(dest) %>% summarise(unique = n_distinct(carrier)) %>% arrange(desc(unique))`\nRank the carriers according to number of destinations they fly to. (But filtering out some destinations) :\n```{r}\nflights %>%                                       # 336,776 x 19\n  group_by(dest) %>%                              # 336,776 x 19\n  filter(n_distinct(carrier)>=2) %>%              # 325,397 x 19\n  group_by(carrier) %>%                           # 325,397 x 19. THIS `group_by` REPLACES the previous one (??)\n  summarise(carrier_dests = n_distinct(dest)) %>% # 16 x 2 ...`carrier`, `carrier_dests`\n  arrange(desc(carrier_dests))                    # 16 x 2 ...`carrier`, `carrier_dests`\n```\n\nThis gives same answer. But I don't know how the `count()` works, nor why 2 of them are needed (but they are) :\n```{r}\nflights %>%                                       # 336,776 x 19\n  group_by(dest) %>%                              # 336,776 x 19\n  filter(n_distinct(carrier)>=2) %>%              # 325,397 x 19\n  count(carrier) %>%                              # 285 x 3 ...dest, carrier, n. THIS did the job of a summarise() ?\n  group_by(carrier) %>%                           # 285 x 3 ...dest, carrier, n\n  count(sort = TRUE)                              # 16 x 2 ...carrier, nn\n```\n\n-----------\n\nQ8. For each plane, count the number of flights before the first delay of greater than 1 hour\n[This was previously s5.6.7 Exercises Q6]\n\nA8. [3 snippets+comments (not mine). 2&3 give same 3748x2 answer. I don't follow any - all use unfamiliar patterns]\n\n_This uses a grouped summary operation. First I group by plane (`tailnum`), then I create a variable\nthat defines the row number within each plane. I then filter the data to only include flights with\ndelays longer than an hour, and use `summarize()` in conjunction with `first()` to find for each plane\nthe `row_num` of the first flight with an 1+ hour delay. I subtract 1 from that value to count the\nnumber of flights before the first delay, rather than including the first flight with the hour or more delay_\n```{r}\nflights %>%\n  group_by(tailnum) %>%\n  mutate(row_num = row_number()) %>%\n  filter(arr_delay > 60) %>%\n  summarize(first_hour_delay = first(row_num) - 1)\n```\n\n\n_I think this requires grouped mutate (but I may be wrong) :_\n```{r}\nflights %>%\n  arrange(tailnum, year, month, day) %>%\n  group_by(tailnum) %>%\n  mutate(delay_1hr = arr_delay > 60) %>%\n  mutate(before_1stdelay = cumsum(delay_1hr)) %>%\n  filter(before_1stdelay < 1) %>%\n  count(sort = TRUE)\n```\n\n\n```{r}\nflights %>%\n  mutate(dep_date = as.Date(time_hour)) %>%\n  group_by(tailnum) %>%\n  arrange(dep_date) %>%\n  filter(!cumany(arr_delay > 60)) %>%\n  tally(sort = TRUE)\n```\n\n\n",
    "created" : 1516901994355.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3379374584",
    "id" : "37C50A4A",
    "lastKnownWriteTime" : 1517355112,
    "last_content_update" : 1517355112057,
    "path" : "~/Dropbox/repos/R4DS_1217/R4DS_Chapter05.Rmd",
    "project_path" : "R4DS_Chapter05.Rmd",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}